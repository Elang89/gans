{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cycle GAN in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "from utils import Logger\n",
    "\n",
    "import os, urllib, zipfile, itertools\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd.variable import Variable\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = './torch_data/CycleGAN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_DATA_NAMES = [\"ae_photos\", \"apple2orange\", \"summer2winter_yosemite\", \"horse2zebra\", \"monet2photo\", \"cezanne2photo\", \"ukiyoe2photo\", \"vangogh2photo\", \"maps\", \"cityscapes\",\"facades\",\"iphone2dslr_flower\",\"mini\", \"mini_pix2pix\", \"mini_colorization\"]\n",
    "\n",
    "URL = 'https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets/{}.zip'\n",
    "class DownloadProgressBar(tqdm):\n",
    "    def update_to(self, b=1, bsize=1, tsize=None):\n",
    "        if tsize is not None:\n",
    "            self.total = tsize\n",
    "        self.update(b * bsize - self.n)\n",
    "\n",
    "def rename_images(rootdir):\n",
    "    for subdir, dirs, files in os.walk(rootdir):\n",
    "        idx = 0\n",
    "        for file in files:\n",
    "            file_path = os.path.join(subdir, file)\n",
    "            new_file_path = os.path.join(subdir, \"{}.jpg\".format(idx))\n",
    "            os.rename(file_path, new_file_path)\n",
    "            idx = idx + 1\n",
    "        \n",
    "def download_cyclegan_dataset(filename, path, force=False):\n",
    "    # Validate dataset filename is valid.\n",
    "    assert(filename in VALID_DATA_NAMES)\n",
    "    # Return if path exists.\n",
    "    file_path = \"{}/{}.zip\".format(path, filename)\n",
    "    if os.path.exists(file_path) and not force: return\n",
    "    # Otherwise download.\n",
    "    \n",
    "    # Make path directory if missing.\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    # Download data\n",
    "    url = URL.format(filename)\n",
    "    with DownloadProgressBar(unit='B', unit_scale=True,\n",
    "                             miniters=1, desc=url.split('/')[-1]) as t:\n",
    "        urllib.request.urlretrieve(url, file_path, reporthook=t.update_to)\n",
    "        with zipfile.ZipFile(file_path, 'r') as zip_obj:\n",
    "            zip_obj.extractall(path)\n",
    "    rename_images(os.path.join(path, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "vangogh2photo.zip: 307MB [02:06, 2.41MB/s]                               \n",
      "maps.zip: 1.48GB [09:10, 2.68MB/s]                               \n",
      "cityscapes.zip: 8.19kB [00:00, 12.8kB/s]\n",
      "facades.zip: 35.1MB [00:33, 1.06MB/s]                            \n",
      "iphone2dslr_flower.zip:  43%|████▎     | 146M/340M [01:01<01:13, 2.66MB/s]   "
     ]
    }
   ],
   "source": [
    "for name in VALID_DATA_NAMES:\n",
    "    download_cyclegan_dataset(name, DATA_FOLDER, force=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CycleGanDataset(Dataset):\n",
    "    \"\"\"My dataset.\"\"\"\n",
    "    \n",
    "    def __init__(self, path, transform=None):\n",
    "        self._path = path\n",
    "        self.num_files = len(os.listdir(self._path))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_files\n",
    "    \n",
    "    def filename(self, idx):\n",
    "        for directory in [\"trainA\", \"testA\"]:\n",
    "            possible_path = os.path.join(self._path, directory, \"{}.jpg\".format(str(idx)))\n",
    "            if os.path.exists(possible_path):\n",
    "                return possible_path\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Handle vectors.\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        img_name = self.filename(idx)\n",
    "        print(img_name)\n",
    "        image = Image.fromarray(io.imread(img_name))\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "    def visualize(self, idx):\n",
    "        np_img = np.transpose(self[idx].numpy(), (1,2, 0))\n",
    "        plt.imshow(np_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cyclegan_dataset():\n",
    "    compose = transforms.Compose(\n",
    "        [transforms.Resize((80, 80)),\n",
    "         transforms.ToTensor(),\n",
    "         transforms.Normalize((.5,), (.5,))\n",
    "        ])\n",
    "    return CycleGanDataset(DATA_FOLDER + \"/ae_photos\", transform=compose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_A = load_cyclegan_dataset()\n",
    "data_B = load_cyclegan_dataset()\n",
    "\n",
    "# Safety check visualization.\n",
    "data_A.visualize(101)\n",
    "data_B.visualize(101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discriminator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscriminatorNet(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(DiscriminatorNet, self).__init__()\n",
    "        self.conv_0 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64,\n",
    "                                   kernel_size=(4, 4), stride=2),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
    "        )\n",
    "        self.conv_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128,\n",
    "                                   kernel_size=(4, 4), stride=2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
    "        )\n",
    "        self.conv_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=256,\n",
    "                                   kernel_size=(4, 4), stride=2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
    "        )\n",
    "        self.conv_3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=512,\n",
    "                                   kernel_size=(4, 4), stride=2),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
    "        )\n",
    "        self.conv_out = nn.Conv2d(in_channels=512, out_channels=1,\n",
    "                             kernel_size=(4, 4), stride=2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_0(x)\n",
    "        x = self.conv_1(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.conv_3(x)\n",
    "        x = self.conv_out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dis_a = DiscriminatorNet()\n",
    "Dis_b = DiscriminatorNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorNet(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(GeneratorNet, self).__init__()\n",
    "        \n",
    "        # c7s1-64\n",
    "        self.conv_0 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=(7, 7), stride=1, \n",
    "                      padding_mode='reflect'),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        # d128\n",
    "        self.conv_1 = nn.Sequential( \n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3), stride=2,\n",
    "                      padding_mode='reflect'),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        # d256\n",
    "        self.conv_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3, 3), stride=2,\n",
    "                     padding_mode='reflect'),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        # R256\n",
    "        self.res_3 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(3, 3),\n",
    "                               stride=2),\n",
    "        # R256\n",
    "        self.res_4 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(3, 3),\n",
    "                               stride=2),\n",
    "        # R256\n",
    "        self.res_5 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(3, 3),\n",
    "                               stride=2),\n",
    "        # R256\n",
    "        self.res_6 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(3, 3),\n",
    "                               stride=2),\n",
    "        # R256\n",
    "        self.res_7 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(3, 3),\n",
    "                               stride=2),\n",
    "        # R256\n",
    "        self.res_8 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(3, 3),\n",
    "                               stride=2),\n",
    "        # u128\n",
    "        self.ups_9 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=256, out_channels=128, \n",
    "                               kernel_size=(3, 3), stride=0.5),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        # u64\n",
    "        self.ups_10 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=(3, 3), \n",
    "                               stride=0.5),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        # c7s1-3\n",
    "        self.conv_0 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=3, kernel_size=(7, 7), stride=1, \n",
    "                      padding_mode='reflect'),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "    # TODO(diegoalejogm): Add skip layer connections.    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_0(x)\n",
    "        x = self.conv_1(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.res_3(x)\n",
    "        x = self.res_4(x)\n",
    "        x = self.res_5(x)\n",
    "        x = self.res_6(x)\n",
    "        x = self.res_7(x)\n",
    "        x = self.res_8(x)\n",
    "        x = self.ups_9(x)\n",
    "        x = self.ups_10(x)\n",
    "        x = self.conv_11(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GeneratorNet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2ea9ceb059e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mGen_a2b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGeneratorNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mGen_b2a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGeneratorNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'GeneratorNet' is not defined"
     ]
    }
   ],
   "source": [
    "Gen_a2b = GeneratorNet()\n",
    "Gen_b2a = GeneratorNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.BCELoss()\n",
    "gan_loss_f = nn.MSELoss()\n",
    "cycle_loss_f = nn.L1Loss()\n",
    "\n",
    "g_optimizer = torch.optim.Adam(itertools.chain(Gen_a2b.parameters(), Gen_b2a.parameters()), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "d_optimizer = torch.optim.Adam(itertools.chain(Dis_A.parameters(), Dis_B.parameters()), lr=0.0002, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_data_label(size):\n",
    "    '''\n",
    "    Tensor containing ones, with shape = size\n",
    "    '''\n",
    "    data = Variable(torch.ones(size, 1))\n",
    "    if torch.cuda.is_available(): return data.cuda()\n",
    "    return data\n",
    "\n",
    "def fake_data_label(size):\n",
    "    '''\n",
    "    Tensor containing ones, with shape = size\n",
    "    '''\n",
    "    data = Variable(torch.zeros(size, 1))\n",
    "    if torch.cuda.is_available(): return data.cuda()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(gan_loss_f, cycle_loss_f, \n",
    "                    generator_a2b, generator_b2a, \n",
    "                    real_data, fake_data, lambd):\n",
    "    \n",
    "    def adversarial_loss(loss_fn, fake_data):\n",
    "        # Calculate loss for D(G(x)), x being a \"fake\" sample, treating it as positive.\n",
    "        prediction = discriminator(fake_data)\n",
    "        return loss_fn(prediction, real_data_label(fake_data.size(0)))\n",
    "    \n",
    "    def cycle_loss(loss_fn, lambd, generator_first, generator_second, real_data):\n",
    "        # Calculate loss for cycle F(G(x)), compared to `real_data` sample.\n",
    "        fake_data = generator_first(real_data)\n",
    "        recons_data = generator_second(fake_data)\n",
    "        return loss_fn(recons, recons_data) * lambd\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Calculate adversarial loss for each generator.\n",
    "    gen_A_loss = adversarial_loss()\n",
    "    gen_B_loss = adversarial_loss()\n",
    "    \n",
    "    # Calculate Cycle consistency loss for generators in each domain (A, B).\n",
    "    cycle_loss_A = cycle_loss()\n",
    "    cycle_loss_B = cycle_loss()\n",
    "    \n",
    "    # Compute full generator loss.\n",
    "    gen_full_loss = (\n",
    "        (gen_A_loss + gen_B_loss) + # Generator loss \n",
    "        (cycle_loss_A + cycle_loss_B) # Cycle consistency loss\n",
    "    )\n",
    "\n",
    "    # Back propagate the loss.\n",
    "    gen_full_loss.backward()\n",
    "    g_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator():\n",
    "    \n",
    "    def adversarial_loss(loss_fn, discriminator, real_data, fake_data):\n",
    "        # Calculate loss for D(G(x)), x being a \"fake\" sample.\n",
    "        prediction = discriminator(fake_data)\n",
    "        loss_fake_data = loss_fn(prediction, fake_data_label(fake_data.size(0)))\n",
    "        \n",
    "        # Calculate loss for D(G(x)), x being a \"real\" sample.\n",
    "        prediction_real = discriminator(real_data)\n",
    "        loss_real_data = loss_fn(prediction, real_data_label(real_data.size(0)))\n",
    "        \n",
    "        return loss_fake_data + loss_real_data\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Compute adversarial loss for each discriminator.\n",
    "    disc_A_loss = adversarial_loss()\n",
    "    disc_B_loss = adversarial_loss()\n",
    "    \n",
    "    # Compute full discriminator loss.\n",
    "    disc_full_loss = disc_A_loss + disc_B_loss\n",
    "\n",
    "    # Backward propagate.\n",
    "    disc_full_loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "for i, (a_real, b_real) in enumerate(zip(data_A, data_B)):\n",
    "    a_real = Variable(a_real[0])\n",
    "    b_real = Variable(b_real[0])\n",
    "    a_real, b_real = utils.cuda([a_real, b_real])\n",
    "\n",
    "    a_fake = self.G_b2a(b_real)\n",
    "    b_fake = self.G_a2b(a_real)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
