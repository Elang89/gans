{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "from utils import Logger\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd.variable import Variable\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = './torch_data/VGAN/MNIST'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_data():\n",
    "    compose = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize([0.5], [0.5])\n",
    "        ])\n",
    "    out_dir = '{}/dataset'.format(DATA_FOLDER)\n",
    "    return datasets.MNIST(root=out_dir, train=True, transform=compose, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elang/Projects/Python/gans/.venv/lib/python3.9/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data = mnist_data()\n",
    "# Create loader with data, so that we can iterate over it\n",
    "data_loader = torch.utils.data.DataLoader(data, batch_size=100, shuffle=True)\n",
    "# Num batches\n",
    "num_batches = len(data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscriminatorNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    A three hidden-layer discriminative neural network\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(DiscriminatorNet, self).__init__()\n",
    "        n_features = 784\n",
    "        n_out = 1\n",
    "        \n",
    "        self.hidden0 = nn.Sequential( \n",
    "            nn.Linear(n_features, 2048),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.hidden1 = nn.Sequential(\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.hidden2 = nn.Sequential(\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.out = nn.Sequential(\n",
    "            torch.nn.Linear(512, n_out),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden0(x)\n",
    "        x = self.hidden1(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "    \n",
    "def images_to_vectors(images):\n",
    "    return images.view(images.size(0), 784)\n",
    "\n",
    "def vectors_to_images(vectors):\n",
    "    return vectors.view(vectors.size(0), 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    A three hidden-layer generative neural network\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(GeneratorNet, self).__init__()\n",
    "        n_features = 100\n",
    "        n_out = 784\n",
    "        \n",
    "        self.hidden0 = nn.Sequential(\n",
    "            nn.Linear(n_features, 512),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.hidden1 = nn.Sequential(            \n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.hidden2 = nn.Sequential(\n",
    "            nn.Linear(1024, 2048),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        \n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(2048, n_out),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden0(x)\n",
    "        x = self.hidden1(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "    \n",
    "# Noise\n",
    "def noise(size):\n",
    "    n = Variable(torch.randn(size, 100))\n",
    "    if torch.cuda.is_available(): return n.cuda() \n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "discriminator = DiscriminatorNet()\n",
    "generator = GeneratorNet()\n",
    "if torch.cuda.is_available():\n",
    "    discriminator.cuda()\n",
    "    generator.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
    "g_optimizer = optim.Adam(generator.parameters(), lr=0.0002)\n",
    "\n",
    "# Loss function\n",
    "loss = nn.BCELoss()\n",
    "\n",
    "# Number of steps to apply to the discriminator\n",
    "d_steps = 1  # In Goodfellow et. al 2014 this variable is assigned to 1\n",
    "# Number of epochs\n",
    "num_epochs = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_data_target(size):\n",
    "    '''\n",
    "    Tensor containing ones, with shape = size\n",
    "    '''\n",
    "    data = Variable(torch.ones(size, 1))\n",
    "    if torch.cuda.is_available(): return data.cuda()\n",
    "    return data\n",
    "\n",
    "def fake_data_target(size):\n",
    "    '''\n",
    "    Tensor containing zeros, with shape = size\n",
    "    '''\n",
    "    data = Variable(torch.zeros(size, 1))\n",
    "    if torch.cuda.is_available(): return data.cuda()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator(optimizer, real_data, fake_data):\n",
    "    # Reset gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # 1.1 Train on Real Data\n",
    "    prediction_real = discriminator(real_data)\n",
    "    # Calculate error and backpropagate\n",
    "    error_real = loss(prediction_real, real_data_target(real_data.size(0)))\n",
    "    error_real.backward()\n",
    "\n",
    "    # 1.2 Train on Fake Data\n",
    "    prediction_fake = discriminator(fake_data)\n",
    "    # Calculate error and backpropagate\n",
    "    error_fake = loss(prediction_fake, fake_data_target(real_data.size(0)))\n",
    "    error_fake.backward()\n",
    "    \n",
    "    # 1.3 Update weights with gradients\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Return error\n",
    "    return error_real + error_fake, prediction_real, prediction_fake\n",
    "\n",
    "def train_generator(optimizer, fake_data):\n",
    "    # 2. Train Generator\n",
    "    # Reset gradients\n",
    "    optimizer.zero_grad()\n",
    "    # Sample noise and generate fake data\n",
    "    prediction = discriminator(fake_data)\n",
    "    # Calculate error and backpropagate\n",
    "    error = loss(prediction, real_data_target(prediction.size(0)))\n",
    "    error.backward()\n",
    "    # Update weights with gradients\n",
    "    optimizer.step()\n",
    "    # Return error\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Samples for Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_samples = 16\n",
    "test_noise = noise(num_test_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x1152 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3/200], Batch Num: [100/600]\n",
      "Discriminator Loss: 0.0000, Generator Loss: 45.8719\n",
      "D(x): 1.0000, D(G(z)): 0.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1942/2618999336.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m             )\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# Model Checkpoints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Projects/Python/gans/utils.py\u001b[0m in \u001b[0;36msave_models\u001b[0;34m(self, generator, discriminator, epoch)\u001b[0m\n\u001b[1;32m    117\u001b[0m         torch.save(generator.state_dict(),\n\u001b[1;32m    118\u001b[0m                    '{}/G_epoch_{}'.format(out_dir, epoch))\n\u001b[0;32m--> 119\u001b[0;31m         torch.save(discriminator.state_dict(),\n\u001b[0m\u001b[1;32m    120\u001b[0m                    '{}/D_epoch_{}'.format(out_dir, epoch))\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/Python/gans/.venv/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0m_check_dill_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/Python/gans/.venv/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/Python/gans/.venv/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "logger = Logger(model_name='VGAN', data_name='MNIST')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for n_batch, (real_batch,_) in enumerate(data_loader):\n",
    "\n",
    "        # 1. Train Discriminator\n",
    "        real_data = Variable(images_to_vectors(real_batch))\n",
    "        if torch.cuda.is_available(): real_data = real_data.cuda()\n",
    "        # Generate fake data\n",
    "        fake_data = generator(noise(real_data.size(0))).detach()\n",
    "        # Train D\n",
    "        d_error, d_pred_real, d_pred_fake = train_discriminator(d_optimizer,\n",
    "                                                                real_data, fake_data)\n",
    "\n",
    "        # 2. Train Generator\n",
    "        # Generate fake data\n",
    "        fake_data = generator(noise(real_batch.size(0)))\n",
    "        # Train G\n",
    "        g_error = train_generator(g_optimizer, fake_data)\n",
    "        # Log error\n",
    "        logger.log(d_error, g_error, epoch, n_batch, num_batches)\n",
    "\n",
    "        # Display Progress\n",
    "        if (n_batch) % 100 == 0:\n",
    "            display.clear_output(True)\n",
    "            # Display Images\n",
    "            test_images = vectors_to_images(generator(test_noise)).data.cpu()\n",
    "            logger.log_images(test_images, num_test_samples, epoch, n_batch, num_batches);\n",
    "            # Display status Logs\n",
    "            logger.display_status(\n",
    "                epoch, num_epochs, n_batch, num_batches,\n",
    "                d_error, g_error, d_pred_real, d_pred_fake\n",
    "            )\n",
    "        # Model Checkpoints\n",
    "        logger.save_models(generator, discriminator, epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
